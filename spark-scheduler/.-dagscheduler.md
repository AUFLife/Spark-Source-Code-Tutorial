### Spark源码分析-DAGScheduler

### 主题

* 打通Spark系统运行内幕机制循环流程

#### 引言

通过DAGScheduler面向整个Job，然后划分成不同的Stage，Stage是从后往前划分的，执行的时候是从前往后执行的，每个Stage内部有一系列任务，前面有分享过，任务是并行计算。DAGScheduler会以TaskSet的方式把我们一个DAG构造的Stage中所有任务提交给底层的调度器TaskScheduler，TaskScheduler是一个接口，它作为为接口好处就是更具体的任务调到器解耦合，就样Spark 就可以运行在不同的调度模式上，包括可以让它运行在 Standalone、Yarn、Mesos。希望这篇文章能为读者带出以下的启发。

* 了解Spark系统运行内幕机制循环流程

### Job Stage 划分算法解密

DAGSchduler概述，是一个面向Stage层的调度器

主要入参有：

dagScheduler.runJob\(rdd, cleanedFunc, partitions, callSite, allowLocal, resultHandler, localProperties.get\)

 rdd:find RDD

cleandFunc:计算每个分区的函数

resultHandler:结果侦听器

主要功能如下：

1、接收用户提交的job；

2、将job划分为不同的Stage，这里参考**Stage的划分**，记录哪些RDD、Stage被物化，并且在每一个Stage内产生一系列的task，并封装成TaskSet传递到executor上执行；

3、决定每个task的最佳位置（任务在数据所在的节点上），并结合当前缓存情况；将TaskSet提交给TaskScheduler；

4、重新提交Shuffle输出丢失的Stage给TaskScheduler；

注：一个Stage内部的错误不是由Shuffle造成的，DAGScheduler是不管的，由TaskScheduler负责尝试重新提交task执行；

---

下面说下DAGScheduler的架构其实非常简单

1.eventQueue，所有需要DAGSchduler处理的事情都要往eventQueue中发送event

2. eventProcess Loop Thread，会不断的从eventQueue中获取event处理

3. 实现TaskSchedulerListener，并注册到TaskScheduler，这样TaskScheduler可以随时调用TaskSchedulerListener中的接口报告状况变更

TaskSchedulerListener的实现也就是post各种event到eventQueue

