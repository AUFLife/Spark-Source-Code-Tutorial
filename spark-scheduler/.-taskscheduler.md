### Spark源码分析-DAGScheduler

#### 引言

通过DAGScheduler面向整个Job，然后划分成不同的Stage，Stage是从后往前划分的，执行时是从前往后执行，每个Stage内部有一系列任务。DAGScheduler会以TaskSet的方式把一个DAG构造的Stage中所有任务提交给底层的调度器TaskScheduler，TaskScheduler是一个接口，它作为接口的好处就是更具体的任务调度解耦合，这样Spark就可以运行在不同的调度模式上，包括Standalone、Yarn、Mesos。

* 了解Spark系统运行内幕机制循环流程

#### Spark系统运行内幕机制循环流程

DAGSchedule在提交TaskSet给底层调度器的时候是面向接口TaskScheduler的，这符合面向对象中依赖抽象而不依赖具体的原则，带来底层资源调度的可插拔性。Spark可以运行在众多的资源调度器的模式上，例如 Standalone 、Yarn、Mesos、Local、EC2、其它自定义的资源调度器；在 Standalone 的模式下，我们聚焦于 TaskSchedulerImpl。它会通过TaskSet Manager管理具体的任务。

![img](http://images2015.cnblogs.com/blog/1005794/201702/1005794-20170228145217048-1432062156.png)

TaskScheduler的核心任务是提交TaskSet到集群运算并汇报结果![img](http://images2015.cnblogs.com/blog/1005794/201703/1005794-20170301003410095-59554344.png)

![img](http://images2015.cnblogs.com/blog/1005794/201703/1005794-20170301003611548-1528658067.png)

![QQ截图20170906162615](C:\Users\user\Desktop\QQ截图20170906162615.png)

1. TaskScheduler为TaskSet创建和维护一个TaskSetManager并追踪任务的本地性以及错误信息；遇到Struggle任务时会放到其他节点进行重试；

2. TaskScheduler必须向DAGScheduler汇报执行情况，包括在Shuffle输出lost的时候报告fetch faild等错误信息；

3. TaskScheduler内部会握有SchedulerBackend，它主要是负责管理Executor资源的，从Standalone的模式来讲具体实现是：SparkDeploySchedulerBackend;下图是SchedulerBackend的源码。

   ![QQ截图20170906162757](C:\Users\user\Desktop\QQ截图20170906162757.png)

SparkDepleySchedulerBackend专门收集Worker上的资源信息。它会接受Worker向Driver注册的信息，而这个注册其实就是ExecutorBackend启动的时候为我们当前应用程序准备的计算资源，以进程为单位的。

SparkDeploySchedulerBackend在启动的时候构造AppClient实例并在该实例start的时候启动了ClientEndpoint这个消息循环体，ClientEndpoint在启动时会向Master注册当前程序。