### Spark源码分析-TaskScheduler

#### 引言

通过DAGScheduler面向整个Job，然后划分成不同的Stage，Stage是从后往前划分的，执行时是从前往后执行，每个Stage内部有一系列任务。DAGScheduler会以TaskSet的方式把一个DAG构造的Stage中所有任务提交给底层的调度器TaskScheduler，TaskScheduler是一个接口，它作为接口的好处就是更具体的任务调度解耦合，这样Spark就可以运行在不同的调度模式上，包括Standalone、Yarn、Mesos。

* 了解Spark系统运行内幕机制循环流程

#### Spark系统运行内幕机制循环流程

DAGSchedule在提交TaskSet给底层调度器的时候是面向接口TaskScheduler的，这符合面向对象中依赖抽象而不依赖具体的原则，带来底层资源调度的可插拔性。Spark可以运行在众多的资源调度器的模式上，例如 Standalone 、Yarn、Mesos、Local、EC2、其它自定义的资源调度器；在 Standalone 的模式下，我们聚焦于 TaskSchedulerImpl。它会通过TaskSet Manager管理具体的任务。

![](http://images2015.cnblogs.com/blog/1005794/201702/1005794-20170228145217048-1432062156.png)

TaskScheduler的核心任务是提交TaskSet到集群运算并汇报结果![](http://images2015.cnblogs.com/blog/1005794/201703/1005794-20170301003410095-59554344.png)

![](http://images2015.cnblogs.com/blog/1005794/201703/1005794-20170301003611548-1528658067.png)

1. TaskScheduler为TaskSet创建和维护一个TaskSetManager并追踪任务的本地性以及错误信息；遇到Struggle任务时会放到其他节点进行重试；

2. TaskScheduler必须向DAGScheduler汇报执行情况，包括在Shuffle输出lost的时候报告fetch faild等错误信息；

3. TaskScheduler内部会握有SchedulerBackend，它主要是负责管理Executor资源的，从Standalone的模式来讲具体实现是：SparkDeploySchedulerBackend;下图是SchedulerBackend的源码。

   ![](file://C:\Users\user\Desktop\QQ截图20170906162757.png?lastModify=1504798729)

SparkDepleySchedulerBackend专门收集Worker上的资源信息。它会接受Worker向Driver注册的信息，而这个注册其实就是ExecutorBackend启动的时候为我们当前应用T程序准备的计算资源，以进程为单位的。

SparkDeploySchedulerBackend在启动的时候构造AppClient实例并在该实例start的时候启动了ClientEndpoint这个消息循环体，ClientEndpoint在启动时会向Master注册当前程序。

SparkDeploySchedulerBackend的父类CoraseGraniedExecutorBackend在start的时候会实例化类型为DriverEndpoint（这是我们程序运行的经典的对象Driver，所以的Executor启动时都需要向它注册）的消息循环体，当ExecutorBackend启动的时候会发送RegisterExecutor信息向DriverEndpoint注册，此时SparkDeploySchedulerBackend就掌握了当前应用程序的计算资源，TaskScheduler就是通过SparkDeploySchedulerBackend的计算资源来具体执行Task。（SparkDeploySchedulerBackend在整个应用程序启动一次就行了）

`SparkContext、DAGScheduler、TaskSchedulerImpl、SparkDeploySchedulerBackend在应用程序启动的时候只实例化一次，`应用程序存在期间始终存在这些对象；应用程序的的管理主要是通过DAGScheduler和TaskScheduler，SparkDeploySchedulerBackend是帮助应用程序的Task获取具体的计算资源并把Task分发到集群中。

#### 总结

```markdown
【注意：此源码分析基于Spark 1.6版本，目前Spark 2.X中SparkDeploySchedulerBackend 已改为 SparkStandaloneSchedulerBackend.】
```

* SparkContext实例化时调用createTaskScheduler来创建TaskSchedulerImpl和SparkDeploySchedulerBackend。
* 同时在SparkContext实例化的时候会调用TaskSchedulerImpl的start\(\)方法，在该start\(\)方法中会调用SparkDeployScheduleBackend的start\(\)，在该start\(\)方法中会创建AppClient对象并调用AppClient对象并调用AppClient的start\(\)方法。

* SparkDeploySchedulerBackend 的启动首先调用父类 CoarseGrainedSchedulerBackend 的 start 方法，其中创建了一个 driverEndpoint，它是一个本地的 driver，以 RPC 的方式与其他 executor 通信。

* 在该start\(\)方法中会创建ClientEndpoint（// Just launch an rpcEndpoint; it will call back into the listener.）。

* 在创建SparkDeploySchedulerBackend时会调用父类的start\(\)方法，并传入Command来指定具体为当前应用程序启动的Executor进程的入口类名称为CoarseGrainedExecutorBackend。  
  然后ClientEndpoint启动并通过tryRegisterMaster来注册当前的Application到Master中。

* Master接受到注册信息后，则会为该程序生产ApplicationID并反馈给AppClient，而后通过scheduler来分配资源，具体计算资源的分配是通过应用程序运行方式、Memory、cores等配置来决定的，最后Master会发送指令给Worker。

* Worker中为当前应用程序分配计算资源时会首先分配ExecutorRunner，ExecutorRunner内部会通过Thread的方式构成ProcessBuilder来启动另外一个JVM进程。这个JVM进程启动时候会加载main方法所在的类的名称就是在创建ClientEndpoint时传入的Command来指定具体名称为CoarseGrainedExecutorBackend。

* 此时JVM在通过ProcessBuilder启动的时候获得CoarseGrainedExecutorBackend后加载并调用其中的main方法，在main方法中会实例化CoarseGrainedExecutorBackend本身这个消息循环体，而CoarseGrainedExecutorBackend在实例化时会通过回掉onStart\(\)向DriverEndpoint发送RegisterExecutor来注册当前的CoarseGrainedExecutorBackend。

* 此时DriverEndpoint收到该注册信息并保存了SparkDeploySchedulerBackend实例到内存数据结构中，这样Driver就获得了计算资源！（具体代码流程可以见）

Spark

Master中scheduleExecutorsOnWorkers\(\)方法涉及Spark分配资源的算法：（每当集群资源发生变化时，active master进程为所有已注册的并且没有调度完毕的application调度Worker节点上的Executor进程。）

spark提供了两种资源调度算法：spreadOut和非spreadOut。spreadOut算法会尽可能将一个application所需要的Executor进程分布在多个worker节点上，从而提高并行度，非spreadOut与之相反，他会把一个worker节点的freeCores都耗尽才会去下一个worker节点分配。

Executor资源申请详解

[http://www.cnblogs.com/francisYoung/p/5205420.html](http://www.cnblogs.com/francisYoung/p/5205420.html)

[http://www.cnblogs.com/barrenlake/p/4891589.html](http://www.cnblogs.com/barrenlake/p/4891589.html)

