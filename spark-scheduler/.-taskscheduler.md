 Task运行期之函数调用关系分析&存储子系统分析

摘要：本篇主要讲述在TaskRunner中执行的业务逻辑是如何被调用到的，另外试图运行着的task任务的输入数据从哪获取，处理结果返回到哪里，如何返回；以及对存储子系统进行分析。

一、Task运行期之函数调用关系分析

### 概要

### 准备
spark已经安装完毕
spark运行在local mode或local-cluster mode
local-cluster mode
local-cluster模式也称为伪分布式，可以使用如下指令运行

MASTER=local[1,2,1024] bin/spark-shell

[1,2,1024] 分别表示，executor number, core number和内存大小，其中内存大小不应小于默认的512M


### Driver Programmer初始化过程分析
#### 初始化过程的涉及的主要源文件
1. SparkContext.scala       整个初始化过程的入口（实际上只是个入口，主要工作是由SparkEnv来完成）
2. SparkEnv.scala           创建BlockManager, MapOutputTracker, ConnectionManager, CacheManager
3. DAGScheduler.scala       任务提交的入口，即将Job划分成各个stage的关键
4. TaskSchedulerImpl.scala  决定每个stage可以运行几个task，每个task分别在哪个executor运行
5. SchedulerBackend         1. 最简单的单机运行模式，看LocalBackend
                            2. 如果是集群模式，看源文件SparkDeploySchedulerBackend类
1. SparkContext.scala         整个初始化过程的入口
2. SparkEnv.scala             创建MapOutputTracker, ShuffleManager, BlockManager等相关关键性组件
3. DAGScheduler.scala         任务提交的入口，即将Job划分成Stage的关键
4. TaskScheduler.scala        决定每个Stage中运行task的数量，以及每个task分别在哪个executor运行
5. SchedulerBackend.scala     1. 单机运行模式，看LocalBackend类
                              2. 集群运行模式，看SparkDeploySchedulerBackend类 
                              3. spark-submit提交Yarn模式，看YarnClusterSchedulerBackend

### 初始化过程步骤详解
1. 根据初始化入参生成SparkConf，再根据SparkConf来创建SparkEnv，SparkEnv会初始化一些关键性组件。
  * SparkEnv ： 为一个运行中的Spark实例保持全部的运行时环境，包括序列化，Akka acctor system, block manager, map output tracker,等等。
  * 一般地，Spark代码搜索SparkEnv通过一个全局的变量，因此所有的线程都能访问相同的SparkEnv，因此可以被访问通过SparkEnv.get的方式

Step 1： 根据初始化入参生成SparkConf，再根据SparkConf来创建SparkEnv，Spark会初始化关键性组件
```
  // This function allows components created by SparkEnv to be mocked in unit tests:
  private[spark] def createSparkEnv(
      conf: SparkConf,
      isLocal: Boolean,
      listenerBus: LiveListenerBus): SparkEnv = {
    SparkEnv.createDriverEnv(conf, isLocal, listenerBus)
  }
  ---

class SparkEnv (
    val executorId: String,
    private[spark] val rpcEnv: RpcEnv,
    val serializer: Serializer,
    val closureSerializer: Serializer,
    val cacheManager: CacheManager,
    val mapOutputTracker: MapOutputTracker,
    val shuffleManager: ShuffleManager,
    val broadcastManager: BroadcastManager,
    val blockTransferService: BlockTransferService,
    val blockManager: BlockManager,
    val securityManager: SecurityManager,
    val httpFileServer: HttpFileServer,
    val sparkFilesDir: String,
    val metricsSystem: MetricsSystem,
    val shuffleMemoryManager: ShuffleMemoryManager,
    val executorMemoryManager: ExecutorMemoryManager,
    val outputCommitCoordinator: OutputCommitCoordinator,
    val conf: SparkConf) extends Logging {
```
Step 2：创建TaskScheduler，并根据Spark的运行模式创建相应的SchedulerBackend，同时启动TaskScheduler，这一步至为关键
```
// Create and start the scheduler
    val (sched, ts) = SparkContext.createTaskScheduler(this, master)    // 这里会根据conf.setMaster("...")内容进行模式匹配，判断是哪种Spark运行模式，最后生成相应的SchedulerBackend和TaskScheduler元组1
    _schedulerBackend = sched
    _taskScheduler = ts
    _dagScheduler = new DAGScheduler(this)
    _heartbeatReceiver.ask[Boolean](TaskSchedulerIsSet)

    // start TaskScheduler after taskScheduler sets DAGScheduler reference in DAGScheduler's
    // 在TaskScheduler设置DAGScheduler中 DAGScheduler的引用之后 启动TaskScheduler
    // constructor
    _taskScheduler.start()
``` 
TaskScheduler.start目的是启动相应的SchedulerBackend，并启动定时器进行检测
```
 override def start() {
    backend.start()   //  

    if (!isLocal && conf.getBoolean("spark.speculation", false)) {
      logInfo("Starting speculative execution thread")
      speculationScheduler.scheduleAtFixedRate(new Runnable {
        override def run(): Unit = Utils.tryOrStopSparkContext(sc) {
          checkSpeculatableTasks()
        }
      }, SPECULATION_INTERVAL_MS, SPECULATION_INTERVAL_MS, TimeUnit.MILLISECONDS)
    }
  }
```

Step 3：将上一步中创建的TaskSchedulerr实例为入参创建DAGScheduler并启动运行
```
在1.5源码中未找到启动位置
518    _dagScheduler = new DAGScheduler(this) 
```
Step 4：启动WEB UI

  _ui =
      if (conf.getBoolean("spark.ui.enabled", true)) {
        Some(SparkUI.createLiveUI(this, _conf, listenerBus, _jobProgressListener,
          _env.securityManager, appName, startTime = startTime))
      } else {
        // For tests, do not enable the UI
        None
      }

RDD的转换过程
还是以最简单的wordcount为例说明rdd的转换过程
sc.textFile("README.md").flatMap(line => line.split(" ")).map(word => (word, 1))

RDD转换小结
小结一下整个RDD转换过程
HadoopRDD->MappedRDD->FlatMappedRDD->MappedRDD->PairRDDFunctions->ShuffleRDD->MapPartitionsRDD
整个转换过程好长啊，这一切的转换都发生在任务提交之前。

---

### 运行过程分析
#### 数据集操作分类
在对任务运行过程中的函数调用关系分析之前，我们也来