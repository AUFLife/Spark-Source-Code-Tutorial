### Spark源码分析-DAGScheduler

#### 引言

通过DAGScheduler面向整个Job，然后划分成不同的Stage，Stage是从后往前划分的，执行时是从前往后执行，每个Stage内部有一系列任务。DAGScheduler会以TaskSet的方式把一个DAG构造的Stage中所有任务提交给底层的调度器TaskScheduler，TaskScheduler是一个接口，它作为接口的好处就是更具体的任务调度解耦合，这样Spark就可以运行在不同的调度模式上，包括Standalone、Yarn、Mesos。

* 了解Spark系统运行内幕机制循环流程

#### Spark系统运行内幕机制循环流程

DAGSchedule在提交TaskSet给底层调度器的时候是面向接口TaskScheduler的，这符合面向对象中依赖抽象而不依赖具体的原则，带来底层资源调度的可插拔性。Spark可以运行在众多的资源调度器的模式上，例如 Standalone 、Yarn、Mesos、Local、EC2、其它自定义的资源调度器；在 Standalone 的模式下，我们聚焦于 TaskSchedulerImpl。它会通过TaskSet Manager管理具体的任务。

![](http://images2015.cnblogs.com/blog/1005794/201702/1005794-20170228145217048-1432062156.png)

TaskScheduler的核心任务是提交TaskSet到集群运算并汇报结果![](http://images2015.cnblogs.com/blog/1005794/201703/1005794-20170301003410095-59554344.png)

![](http://images2015.cnblogs.com/blog/1005794/201703/1005794-20170301003611548-1528658067.png)

1. TaskScheduler为TaskSet创建和维护一个TaskSetManager并追踪任务的本地性以及错误信息；遇到Struggle任务时会放到其他节点进行重试；

2. TaskScheduler必须向DAGScheduler汇报执行情况，包括在Shuffle输出lost的时候报告fetch faild等错误信息；

3. TaskScheduler内部会握有SchedulerBackend，它主要是负责管理Executor资源的，从Standalone的模式来讲具体实现是：SparkDeploySchedulerBackend;下图是SchedulerBackend的源码。

   ![](file://C:\Users\user\Desktop\QQ截图20170906162757.png?lastModify=1504798729)

SparkDepleySchedulerBackend专门收集Worker上的资源信息。它会接受Worker向Driver注册的信息，而这个注册其实就是ExecutorBackend启动的时候为我们当前应用程序准备的计算资源，以进程为单位的。

SparkDeploySchedulerBackend在启动的时候构造AppClient实例并在该实例start的时候启动了ClientEndpoint这个消息循环体，ClientEndpoint在启动时会向Master注册当前程序。

SparkDeploySchedulerBackend的父类CoraseGraniedExecutorBackend在start的时候会实例化类型为DriverEndpoint（这是我们程序运行的经典的对象Driver，所以的Executor启动时都需要向它注册）的消息循环体，当ExecutorBackend启动的时候会发送RegisterExecutor信息向DriverEndpoint注册，此时SparkDeploySchedulerBackend就掌握了当前应用程序的计算资源，TaskScheduler就是通过SparkDeploySchedulerBackend的计算资源来具体执行Task。（SparkDeploySchedulerBackend在整个应用程序启动一次就行了）

`SparkContext、DAGScheduler、TaskSchedulerImpl、SparkDeploySchedulerBackend在应用程序启动的时候只实例化一次，`应用程序存在期间始终存在这些对象；应用程序的的管理主要是通过DAGScheduler和TaskScheduler，SparkDeploySchedulerBackend是帮助应用程序的Task获取具体的计算资源并把Task分发到集群中。

#### 总结

```markdown
【注意：此源码分析基于Spark 1.6版本，目前Spark 2.X中SparkDeploySchedulerBackend 已改为 SparkStandaloneSchedulerBackend.】
```

在SparkContext实例化的时候调用createTaskSchduler来创建TaskSchedulerImpl和SparkDeployScheduler 。同时在SparkContext实例化的时候会调用TaskSchedulerImpl的start\(\)方法。

在该start\(\)方法中会创建ClientEndpoint，在创建ClientEndpoint的时候会传入Command来指定具体当前应用程序启动Executor进程的入口类名称为CoarseGrainedExecutorBackend，此时DriverEndpoint收到该注册信息并保存了SparkDeploySchedulerBackend，然后ClientEndpoint启动并通过tryRegisterMaster来注册当前的应用程序到Master中。

Master接受到注册信息后如何可以运行程序，会为该程序产生JobID并通过scheduler来分配计算资源，具体计算资源的分配方式是通过应用程序运行方式、Memory、cores等配置来决定，最后Master会发送指令给Worker。

Worker中为当前进程启动时会首先分配ExecutorRunner，ExecuteorRunner内部会通过Thread的方式构成ProcessBuilder来启动另外一个JVM进程。这个JVM进程启动时会加载main方法所在的类的名称就是在创建ClientEndpoint时传入的Command来具体指定名称为CoraseGrainedExecutorBackend的类。

此时JVM在通过ProcessBuilder启动的时候获得CoarseGrainedExecutorBackend在实例化后会通过回调onStart\(\)向DriverEndpoint发送RegisterExecutor来注册当前·的CoraseGrainedExecutorBackend。

此时DriverEndpoint收到该注册信息并保存了SparkDeploySchedulerBackend实例的内存数据结构，这样Driver获得了计算资源！具体代码见）

